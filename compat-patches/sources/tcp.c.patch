diff --git a/drivers/net/ovpn/tcp.c b/drivers/net/ovpn/tcp.c
index 289f62c..dca801f 100644
--- a/drivers/net/ovpn/tcp.c
+++ b/drivers/net/ovpn/tcp.c
@@ -7,7 +7,9 @@
  */
 
 #include <linux/skbuff.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
 #include <net/hotdata.h>
+#endif
 #include <net/inet_common.h>
 #include <net/ipv6.h>
 #include <net/tcp.h>
@@ -30,8 +32,14 @@
 
 static struct proto ovpn_tcp_prot __ro_after_init;
 static struct proto_ops ovpn_tcp_ops __ro_after_init;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 16, 0)
+static struct proto ovpn_tcp6_prot;
+static struct proto_ops ovpn_tcp6_ops;
+static DEFINE_MUTEX(tcp6_prot_mutex);
+#else
 static struct proto ovpn_tcp6_prot __ro_after_init;
 static struct proto_ops ovpn_tcp6_ops __ro_after_init;
+#endif
 
 static int ovpn_tcp_parse(struct strparser *strp, struct sk_buff *skb)
 {
@@ -133,13 +141,22 @@ static void ovpn_tcp_rcv(struct strparser *strp, struct sk_buff *skb)
 	if (WARN_ON(!ovpn_peer_hold(peer)))
 		goto err_nopeer;
 	schedule_work(&peer->tcp.defer_del_work);
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 14, 0)
 	dev_dstats_rx_dropped(peer->ovpn->dev);
+#else
+	dev_core_stats_rx_dropped_inc(peer->ovpn->dev);
+#endif
 err_nopeer:
 	kfree_skb(skb);
 }
 
+#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 19, 0)
+static int ovpn_tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len,
+			    int _noblock, int flags, int *addr_len)
+#else
 static int ovpn_tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len,
 			    int flags, int *addr_len)
+#endif
 {
 	int err = 0, off, copied = 0, ret;
 	struct ovpn_socket *sock;
@@ -155,7 +172,17 @@ static int ovpn_tcp_recvmsg(struct sock *sk, struct msghdr *msg, size_t len,
 	peer = sock->peer;
 	rcu_read_unlock();
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 7, 0) || RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(8, 10)
 	skb = __skb_recv_datagram(sk, &peer->tcp.user_queue, flags, &off, &err);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(5, 6, 0) || RHEL_RELEASE_CODE > RHEL_RELEASE_VERSION(8, 0)
+	skb = __skb_recv_datagram(sk, &peer->tcp.user_queue, flags, NULL, &off,
+				  &err);
+#elif LINUX_VERSION_CODE >= KERNEL_VERSION(5, 2, 0)
+	skb = __skb_recv_datagram(sk, flags, NULL, &off, &err);
+#else
+	int peeked = 0;
+	skb = __skb_recv_datagram(sk, flags, NULL, &peeked, &off, &err);
+#endif
 	if (!skb) {
 		if (err == -EAGAIN && sk->sk_shutdown & RCV_SHUTDOWN) {
 			ret = 0;
@@ -268,7 +295,11 @@ static void ovpn_tcp_send_sock(struct ovpn_peer *peer, struct sock *sk)
 
 	if (!peer->tcp.out_msg.len) {
 		preempt_disable();
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 14, 0)
 		dev_dstats_tx_add(peer->ovpn->dev, skb->len);
+#else
+		dev_sw_netstats_tx_add(peer->ovpn->dev, 1, skb->len);
+#endif
 		preempt_enable();
 	}
 
@@ -300,7 +331,11 @@ static void ovpn_tcp_send_sock_skb(struct ovpn_peer *peer, struct sock *sk,
 		ovpn_tcp_send_sock(peer, sk);
 
 	if (peer->tcp.out_msg.skb) {
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 14, 0)
 		dev_dstats_tx_dropped(peer->ovpn->dev);
+#else
+		dev_core_stats_tx_dropped_inc(peer->ovpn->dev);
+#endif
 		kfree_skb(skb);
 		return;
 	}
@@ -321,8 +356,16 @@ void ovpn_tcp_send_skb(struct ovpn_peer *peer, struct sock *sk,
 	spin_lock_nested(&sk->sk_lock.slock, OVPN_TCP_DEPTH_NESTING);
 	if (sock_owned_by_user(sk)) {
 		if (skb_queue_len(&peer->tcp.out_queue) >=
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 9, 0)
 		    READ_ONCE(net_hotdata.max_backlog)) {
+#else
+		    netdev_max_backlog) {
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 14, 0)
 			dev_dstats_tx_dropped(peer->ovpn->dev);
+#else
+			dev_core_stats_tx_dropped_inc(peer->ovpn->dev);
+#endif
 			kfree_skb(skb);
 			goto unlock;
 		}
@@ -524,13 +567,23 @@ int ovpn_tcp_socket_attach(struct ovpn_socket *ovpn_sock,
 		ovpn_sock->sk->sk_prot = &ovpn_tcp_prot;
 		ovpn_sock->sk->sk_socket->ops = &ovpn_tcp_ops;
 	} else {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 16, 0)
+		mutex_lock(&tcp6_prot_mutex);
+		if (!ovpn_tcp6_prot.recvmsg)
+			ovpn_tcp_build_protos(&ovpn_tcp6_prot, &ovpn_tcp6_ops,
+					      ovpn_sock->sk->sk_prot,
+					      ovpn_sock->sk->sk_socket->ops);
+		mutex_unlock(&tcp6_prot_mutex);
+#endif
 		ovpn_sock->sk->sk_prot = &ovpn_tcp6_prot;
 		ovpn_sock->sk->sk_socket->ops = &ovpn_tcp6_ops;
 	}
 
 	/* avoid using task_frag */
 	ovpn_sock->sk->sk_allocation = GFP_ATOMIC;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 2, 0) || RHEL_RELEASE_CODE >= RHEL_RELEASE_VERSION(9, 3)
 	ovpn_sock->sk->sk_use_task_frag = false;
+#endif
 
 	/* enqueue the RX worker */
 	strp_check_rcv(&peer->tcp.strp);
@@ -591,11 +644,22 @@ static void ovpn_tcp_build_protos(struct proto *new_prot,
 /* Initialize TCP static objects */
 void __init ovpn_tcp_init(void)
 {
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(6, 5, 0) && LINUX_VERSION_CODE < KERNEL_VERSION(6, 16, 0)) || \
+	SUSE_PRODUCT_CODE >= SUSE_PRODUCT(1, 15, 6, 0)
+	sendmsg_locked = (sendmsg_locked_t)get_unexported_symbol("sendmsg_locked");
+	if (!sendmsg_locked) {
+		pr_err("sendmsg_locked symbol not found\n");
+		return;
+	}
+#endif
+
 	ovpn_tcp_build_protos(&ovpn_tcp_prot, &ovpn_tcp_ops, &tcp_prot,
 			      &inet_stream_ops);
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(6, 16, 0)
 #if IS_ENABLED(CONFIG_IPV6)
 	ovpn_tcp_build_protos(&ovpn_tcp6_prot, &ovpn_tcp6_ops, &tcpv6_prot,
 			      &inet6_stream_ops);
 #endif
+#endif /* LINUX_VERSION_CODE >= KERNEL_VERSION(6, 16, 0) */
 }
